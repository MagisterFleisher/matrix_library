\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}

\title{Numerical Foundations of Machine Learning:\\From High-Performance Fortran to Quantization Theory}
\author{Technical Briefing}
\date{2026}

\begin{document}

\maketitle

\section{Introduction}
While Python dominates the user-facing interface of Machine Learning (ML), the underlying computational engine relies on High-Performance Computing (HPC) principles. This document explores the transition from Fortran-based numerical kernels to the modern mathematical contention of data-type quantization in distributed GPU environments.

\section{Distributed Parallelism: Coarray Fortran (CAF)}
Fortran 2008 and 2018 introduced native Parallelism via \textbf{Coarrays}. Unlike MPI, which requires explicit library calls for message passing, CAF treats distributed memory as part of the language syntax using "images."

\begin{itemize}
    \item \textbf{Images:} Independent copies of the program running on different processors/nodes.
    \item \textbf{Codimension Syntax:} A variable declared as \texttt{real :: weight[*]} exists on all images. Image 1 can access Image 2's data via \texttt{weight[2]}.
\end{itemize}

In ML, CAF is used to implement \textbf{Data Parallelism}, where each image holds a portion of the global tensor. This reduces the overhead of the "Two-Language Problem" by keeping the distributed logic within the native Fortran compiler.

\section{The Mathematics of Quantization}
In modern research, the assumption of infinite precision ($\mathbb{R}$) is replaced by the constraints of finite hardware. Affine Quantization is the formal mapping of a real-valued tensor to a discrete integer space.

\subsection{The Mapping Function}
To transform a continuous value $x$ into a $k$-bit integer $x_q$:
\begin{equation}
x_q = \text{clamp}\left( \text{round}\left( \frac{x}{S} \right) + Z, q_{min}, q_{max} \right)
\end{equation}

\subsection{Stochastic Rounding (SR)}
Standard "round-to-nearest" can lead to stagnation in ML because tiny gradients are always rounded to zero. Stochastic Rounding treats rounding as a probabilistic event:

\begin{equation}
SR(x) = 
\begin{cases} 
\lfloor x \rfloor + 1 & \text{with probability } x - \lfloor x \rfloor \\
\lfloor x \rfloor & \text{with probability } 1 - (x - \lfloor x \rfloor)
\end{cases}
\end{equation}

\textbf{Mathematical Property:} The expected value of the rounded number is exactly the original value: $E[SR(x)] = x$. This allows researchers to use 8-bit or 16-bit floats for training without losing the "signal" of infinitesimal updates.

\section{Fundamental Challenges for Researchers}
The primary contention in ML mathematics is the \textbf{non-differentiability} of the quantization function. Researchers circumvent this using the \textbf{Straight-Through Estimator (STE)}, treating the gradient of the rounding function as 1 during the backward pass:

\begin{equation}
\frac{\partial L}{\partial x} \approx \frac{\partial L}{\partial x_q} \cdot 1
\end{equation}

\section{Summary of Numerical Formats}
\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{Feature} & \textbf{High-Precision (FP32/64)} & \textbf{Quantized (INT8/4)} \\
\midrule
Numerical Noise & Minimal (Rounding error) & High (Quantization noise) \\
Hardware Speed & Standard & 4x - 10x faster via Tensor Cores \\
Memory Footprint & 32/64 bits per parameter & 8/4 bits per parameter \\
Differentiation & Native (Calculus) & Simulated (STE) \\
\bottomrule
\end{tabular}
\end{center}

\end{document}